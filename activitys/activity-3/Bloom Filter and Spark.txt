import breeze.util.BloomFilter
import org.apache.log4j.BasicConfigurator
import org.apache.log4j.varia.NullAppender
import org.apache.spark.{SparkConf, SparkContext}

object TestBloomFilterErrorRate {
  BasicConfigurator.configure(new NullAppender)
  def main(args: Array[String]): Unit = {

    val conf = new SparkConf().setAppName("TestBloomFilterErrorRate").setMaster("local[*]")
    val sc = new SparkContext(conf)

    val documents = List(
      "However difficult life may seem, there is always something you can do and succeed at"
    )
    val documents2 = List(
      "mahe there"
    )
    val documentsRDD = sc.parallelize(documents)
    val documentsRDD2 = sc.parallelize(documents2)

    val wordsRDD = documentsRDD.flatMap(document => document.toLowerCase().split("\\W+"))
    val wordsRDD2 = documentsRDD2.flatMap(document => document.toLowerCase().split("\\W+"))

    val bloomFilter = wordsRDD.mapPartitions { iter =>
      val bf = BloomFilter.optimallySized[String](1000, 0.001)
      iter.foreach(word => bf += word)
      Iterator(bf)
    }.reduce(_ | _)

    val actualWords = wordsRDD.collect().toSet
    println(s"actualWords: $actualWords")
    val bfResults = wordsRDD2.filter(word => bloomFilter.contains(word)).collect().toSet
    println(s"bfResults : $bfResults")
    val falsePositives = bfResults.size
    println(s"falsePositives : $falsePositives")
    val errorRate = falsePositives.toDouble / actualWords.size

    println(s"Error Rate: $errorRate")
    sc.stop()
  }
}